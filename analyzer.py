# analyzer.py (æ•´å€‹æª”æ¡ˆï¼Œè«‹ç›´æ¥è¦†è“‹)
import json
import re
import datetime
import time
from urllib.parse import urlparse

from langchain_ollama import ChatOllama
from langchain_core.prompts import ChatPromptTemplate

# å°‡ tools çš„å°å…¥æš«æ™‚è¨»è§£æ‰ï¼ˆç”±æ–¼éœ€è¦åœç”¨å·¥å…·å‘¼å«ï¼‰
# from tools import (
#     check_url_safety,
#     analyze_domain_age,
#     check_url_patterns,
#     extract_contact_info,
#     detect_language_anomaly,
# )
# Optional: å¦‚æœä½ æœ‰ SimplePhishingAnalysisï¼Œå¯ä»¥ä¿ç•™ï¼›æœ¬ç‰ˆæœ¬ LLM ç›´æ¥å› JSONï¼Œæˆ‘å€‘ä»¥ dict è™•ç†
# from models import SimplePhishingAnalysis

# ------------------ TOOL REGISTRY & CONFIG ------------------
# å·¥å…·å‘¼å«æš«æ™‚åœç”¨ï¼šå°‡ TOOL_REGISTRY ä¿æŒç‚ºç©ºï¼Œä¸¦è¨»è§£åŸå§‹å·¥å…·å°å…¥ã€‚
TOOL_REGISTRY = {}

SAFE_DOMAINS = {"google.com", "google.com.tw", "microsoft.com", "facebook.com", "github.com", "gov.tw", "edu.tw"}
SUSPICIOUS_TLDS = {".xyz", ".top", ".loan", ".vip", ".click", ".buzz", ".shop", ".loan", ".info", ".ru", ".tk"}
LOG_PATH = "planner_tool_log.jsonl"
MODEL_NAME = "qwen3:8b"

# ------------------ PROMPT (few-shot, JSON, escaped braces) ------------------
plan_prompt = ChatPromptTemplate.from_messages(
    [
        ("system",
         """
ä½ æ˜¯å·¥å…·è·¯ç”±è¦åŠƒå™¨ (Tool Planner)ã€‚ä½ çš„ä»»å‹™ï¼šè®€å– visible_text èˆ‡ urlsï¼Œ**åªæ±ºå®šè¦å‘¼å«å“ªäº›å·¥å…·**ï¼Œä¸è¦çŒœæ¸¬å·¥å…·è¼¸å‡ºå…§å®¹ã€‚
å›è¦†æ ¼å¼ï¼ˆåƒ…è¦ JSONï¼Œä¸€è¡Œæˆ–å¤šè¡Œçš†å¯ï¼‰ï¼š
{{"calls":[{{"tool":"<name>","args":{{...}}}}, ...]}}
å·¥å…·æ¸…å–®ï¼šcheck_url_safety, analyze_domain_age, check_url_patterns, extract_contact_info, detect_language_anomaly
args å¯ç‚ºç©º dictï¼ˆç¨‹å¼æœƒè£œè¶³ï¼‰ï¼Œæœ€å¤š 3 å€‹å‘¼å«ï¼Œç„¡éœ€å·¥å…·æ™‚å›å‚³ {{"calls":[]}}
"""),
        ("human", "visible_text:\n{visible}\n\nurls:\n{urls}\n"),
    ],
)

planner_llm = ChatOllama(model=MODEL_NAME, temperature=0)

# ------------------ HELPERS ------------------
def log_decision(record: dict):
    try:
        with open(LOG_PATH, "a", encoding="utf-8") as f:
            f.write(json.dumps(record, ensure_ascii=False) + "\n")
    except Exception:
        pass

def extract_visible_text(html: str) -> str:
    html = re.sub(r"<(script|style|meta|link|noscript)[^>]*>.*?</\1>", "", html, flags=re.DOTALL)
    blocks = re.findall(r">(.*?)<", html)
    return "\n".join(x.strip() for x in blocks if x.strip())

def find_urls(text: str) -> list:
    return [m.group(1).rstrip('.,;') for m in re.finditer(r"(?i)\b((?:https?://|www\.)\S+)", text)]

def domain_of(url: str) -> str:
    try:
        return urlparse(url).netloc.lower()
    except:
        return ""

def is_suspicious_tld(domain: str) -> bool:
    return any(domain.endswith(tld) for tld in SUSPICIOUS_TLDS)

def contains_brand_typo(domain: str) -> bool:
    # very simple heuristic: common brand substrings with minor typo patterns (1 char different)
    suspicious_patterns = ["paypa", "faceb00k", "chasebannk", "googl", "g00gle", "appleid", "banking-secure"]
    return any(p in domain for p in suspicious_patterns)

def is_safe_domain(domain: str) -> bool:
    return any(domain.endswith(sd) for sd in SAFE_DOMAINS)

# ------------------ PLANNER + TOOL INVOCATION ------------------
ALLOWED_TOOLS = set(TOOL_REGISTRY.keys())

def validate_plan(raw_plan: dict) -> list:
    if not isinstance(raw_plan, dict):
        return []
    calls = raw_plan.get("calls")
    if not isinstance(calls, list):
        return []
    valid_calls = []
    for c in calls[:3]:
        if not isinstance(c, dict):
            continue
        tool = c.get("tool")
        args = c.get("args", {}) or {}
        if tool not in ALLOWED_TOOLS:
            continue
        if not isinstance(args, dict):
            continue
        valid_calls.append({"tool": tool, "args": args})
    return valid_calls

def collect_tool_evidence(urls: list, visible: str) -> dict:
    """
    å·¥å…·èª¿ç”¨å·²è¢«æš«æ™‚åœç”¨ã€‚
    ç›®å‰ç›´æ¥å›å‚³ç©ºçš„ evidence dictï¼Œä¸¦åœ¨æ—¥èªŒä¸­è¨˜éŒ„æ­¤ç‹€æ…‹ä»¥ä¾¿è¿½è¹¤ã€‚
    """
    log_decision({
        "time": datetime.datetime.utcnow().isoformat(),
        "phase": "planner_disabled",
        "visible_snippet": visible[:300],
        "urls": urls[:3],
        "note": "å·¥å…·èª¿ç”¨å·²åœç”¨ï¼ˆcollect_tool_evidence stubï¼‰"
    })
    return {}

# ------------------ RULE-BASED SCORING ------------------
def rule_score(visible: str, urls: list, evidence: dict) -> dict:
    """
    Compute rule-based risk score and reasons.
    Returns: {"score": int, "reasons": [...], "hard_flag": bool}
    """
    score = 0
    reasons = []
    hard_flag = False

    v = visible.lower()
    # keyword groups
    urgent = ["ç«‹å³", "é¦¬ä¸Š", "ç›¡å¿«", "ç·Šæ€¥", "é™æ™‚", "é€¾æœŸ", "è­¦å‘Š", "å¿…é ˆ"]
    auth = ["é©—è­‰", "é‡æ–°é©—è­‰", "å¸³è™Ÿ", "å¯†ç¢¼", "ç™»å…¥", "è§£é™¤é™åˆ¶", "ç¢ºèªèº«åˆ†", "èº«ä»½é©—è­‰"]
    money = ["ä»˜æ¬¾", "è½‰å¸³", "åˆ·å¡", "é‡‘é¡", "åŒ¯æ¬¾", "éŠ€è¡Œ", "ä¿¡ç”¨å¡"]
    click = ["é»æ“Š", "é»æ­¤", "é€£çµ", "href"]

    cnt_urgent = sum(1 for k in urgent if k in v)
    cnt_auth = sum(1 for k in auth if k in v)
    cnt_money = sum(1 for k in money if k in v)
    cnt_click = sum(1 for k in click if k in v)

    # weight and reasons
    if cnt_auth:
        score += cnt_auth * 3
        reasons.append(f"èº«ä»½/é©—è­‰è¦æ±‚ x{cnt_auth}")
    if cnt_money:
        score += cnt_money * 3
        reasons.append(f"é‡‘éŒ¢/ä»˜æ¬¾ç›¸é—œ x{cnt_money}")
    if cnt_urgent:
        score += cnt_urgent * 2
        reasons.append(f"ç·Šæ€¥èªæ°£ x{cnt_urgent}")
    if cnt_click:
        score += cnt_click * 1
        reasons.append(f"è¦æ±‚é»æ“Š x{cnt_click}")

    # URL based checks
    for u in urls:
        d = domain_of(u)
        if not d:
            continue
        # å„ªå…ˆæ¡ç”¨å®‰å…¨è¦å‰‡ï¼šå¦‚æœæ˜¯å®‰å…¨åŸŸåï¼Œè·³éå¯ç–‘æª¢æŸ¥
        if is_safe_domain(d):
            reasons.append(f"å®‰å…¨åŸŸåï¼š{d}")
            # å°å®‰å…¨åŸŸåæ¸›åˆ†ï¼ˆé™ä½é¢¨éšªï¼‰
            score -= 1
        else:
            # åªåœ¨éå®‰å…¨åŸŸåæ™‚æ‰æª¢æŸ¥å¯ç–‘ç‰¹å¾µ
            if is_suspicious_tld(d) or contains_brand_typo(d) or any(x in d for x in ["verify", "secure", "account", "login", "update", "reset"]):
                score += 4
                reasons.append(f"ç–‘ä¼¼å¯ç–‘åŸŸåï¼š{d}")
            # very high risk for credential phishing patterns
            if any(x in d for x in ["-secure-", "login-", "verify-", "account-"]):
                score += 5
                reasons.append(f"åŸŸåå« phishing patternï¼š{d}")

    # Evidence-based bumps (tools)
    for k, v in evidence.items():
        sv = str(v).lower()
        if "suspicious" in sv or "phish" in sv or "malicious" in sv or "blacklist" in sv:
            score += 4
            reasons.append(f"å·¥å…· {k} æ¨™è¨˜å¯ç–‘")
        # domain age returned as very new (example structure) -> bump
        if "created" in sv and "days" in sv:
            # best-effort parse small age -> bump if < 90 days
            m = re.search(r"(\d+)\s*day", sv)
            if m and int(m.group(1)) < 90:
                score += 3
                reasons.append(f"{k}ï¼šç¶²åŸŸå¹´é½¡å°æ–¼90å¤©")

    # JS æ··æ·†æª¢æ¸¬
    from tools import detect_suspicious_js
    html_sample = visible  # ä½¿ç”¨å¯è¦‹æ–‡å­—ä½œç‚ºæª¢æ¸¬æ¨£æœ¬
    js_result = detect_suspicious_js(html_sample)
    if js_result["has_suspicious_js"]:
        if js_result["severity"] == "high":
            score += 5
        elif js_result["severity"] == "medium":
            score += 3
        elif js_result["severity"] == "low":
            score += 1
        reasons.append(f"æª¢æ¸¬åˆ°å¯ç–‘ JavaScriptï¼š{'; '.join(js_result['findings'])}")
    

    # Hard rules: if both auth + urgent present -> high risk regardless
    if cnt_auth >= 1 and cnt_urgent >= 1:
        hard_flag = True
        reasons.append("åŒæ™‚å‡ºç¾èº«ä»½é©—è­‰è¦æ±‚èˆ‡ç·Šæ€¥èªæ°£ï¼ˆå¼·åˆ¶æ¨™è¨˜ï¼‰")

    # clamp and return
    return {"score": max(score, 0), "reasons": reasons, "hard_flag": hard_flag}

# ------------------ LLM CHAIN (analysis with Chain-of-Thought) ------------------
def build_cot_thinking_chain():
    """ç¬¬ä¸€æ­¥ï¼šè®“ LLM é€²è¡Œè‡ªç”±æ–‡å­—æ€è€ƒï¼ˆè¼ƒé«˜ temperatureï¼‰"""
    llm = ChatOllama(model=MODEL_NAME, temperature=0.5)  # Higher temperature for exploration
    prompt = ChatPromptTemplate.from_messages([
        ("system", """
ä½ æ˜¯ä¸€å€‹è³‡å®‰åˆ†æ AIã€‚è«‹é€æ­¥åˆ†æä»¥ä¸‹ä¿¡æ¯ï¼Œä¸¦è©³ç´°èªªæ˜ä½ çš„æ¨ç†éç¨‹ã€‚
è«‹è‡ªç”±åœ°è¡¨é”ä½ çš„æ€è€ƒï¼Œä¸è¦é™åˆ¶æ–¼ä»»ä½•ç‰¹å®šæ ¼å¼ï¼Œå°±åƒåœ¨é€²è¡Œå…§éƒ¨æ¨ç†ã€‚

ä½ éœ€è¦è€ƒæ…®ä»¥ä¸‹å¹¾å€‹æ–¹é¢ï¼š
1. å…§æ–‡ä¸­çš„å¯ç–‘ç‰¹å¾µï¼ˆç·Šæ€¥èªæ°£ã€èº«ä»½é©—è­‰è¦æ±‚ã€é‡‘éŒ¢ç›¸é—œç­‰ï¼‰
2. URL çš„ç‰¹å¾µï¼ˆåŸŸåã€TLDã€å¯ç–‘æ¨¡å¼ç­‰ï¼‰
3. å·¥å…·æª¢æ¸¬çµæœä¸­çš„è­¦å‘Šæ¨™è¨˜
4. æ•´é«”ç¶œåˆåˆ¤æ–·

è«‹é€é»åˆ—å‡ºä½ çš„è§€å¯Ÿå’Œæ¨ç†ã€‚
"""),
        ("human", """
=== ç¶²é å…§æ–‡ ===
{visible_text}

=== URL ===
{urls}

=== å·¥å…·æª¢æ¸¬çµæœ ===
{evidence}

è«‹è©³ç´°èªªæ˜ä½ çš„åˆ†ææ€è·¯å’Œæ¨ç†éç¨‹ï¼Œä½†è«‹å‹¿ç›´æ¥çµ¦å‡ºçµè«–ã€‚
""")
    ])
    return prompt | llm


def build_analysis_chain():
    """ç¬¬äºŒæ­¥ï¼šåŸºæ–¼ CoT æ€è€ƒçµæœï¼Œçµ¦å‡ºåš´æ ¼ JSON åˆ¤æ–·"""
    llm = ChatOllama(model=MODEL_NAME, temperature=0)  # deterministic
    prompt = ChatPromptTemplate.from_messages([
        ("system", """
ä½ æ˜¯ä¸€å€‹è³‡å®‰åˆ†æ AIï¼Œè«‹åŸºæ–¼å‰é¢çš„æ€è€ƒéç¨‹é€²è¡Œæœ€çµ‚åˆ¤æ–·ã€‚
è«‹åš´æ ¼å›å‚³ JSONï¼ˆåªè¼¸å‡º JSONï¼‰ï¼Œæ ¼å¼å¦‚ä¸‹ï¼ˆå‹™å¿…ä½¿ç”¨åˆæ³• JSONï¼‰ï¼š
{{
    "is_potential_phishing": true/false,
    "risk_level": "high"|"medium"|"low",
    "explanation": ["çŸ­ç†ç”±ä¸€","çŸ­ç†ç”±äºŒ"],
    "confidence": 0-100
}}
åªæ ¹æ“šæä¾›çš„æ€è€ƒéç¨‹èˆ‡åŸå§‹å…§æ–‡é€²è¡Œåˆ¤æ–·ï¼Œä¸è¦åŠ å…¥å¤–éƒ¨æœªæä¾›è³‡è¨Šã€‚
è‹¥ä¸ç¢ºå®šï¼Œè«‹çµ¦å‡ºä¸­é–“å€¼ confidence ä¸¦ç”¨ "medium"ã€‚
"""),
        ("human", """
=== ç¶²é å…§æ–‡ ===
{visible_text}

=== URL ===
{urls}

=== å·¥å…·æª¢æ¸¬çµæœ ===
{evidence}

=== å…ˆå‰çš„æ¨ç†éç¨‹ ===
{cot_thinking}

åŸºæ–¼ä»¥ä¸Šæ€è€ƒéç¨‹ï¼Œè«‹çµ¦å‡ºæœ€çµ‚çš„ JSON åˆ¤æ–·ã€‚
""")
    ])
    return prompt | llm

# ------------------ ANALYZE (ä¸»æµç¨‹) ------------------
def analyze_deep(html_text: str) -> dict:
    start = time.time()
    visible = extract_visible_text(html_text)
    urls = find_urls(html_text)
    urls_str = "\n".join(urls[:10]) if urls else "ï¼ˆç„¡ç¶²å€ï¼‰"

    # Collect evidence
    evidence = collect_tool_evidence(urls, visible)

    # Compute rule score
    r = rule_score(visible, urls, evidence)
    score = r["score"]
    reasons = r["reasons"]
    hard_flag = r["hard_flag"]

    # Build evidence_text to LLM (structured but concise)
    def serialize_evidence(ev: dict) -> str:
        parts = []
        for k, v in ev.items():
            s = json.dumps(v, ensure_ascii=False) if not isinstance(v, str) else v
            parts.append(f"{k}: {s}")
        return "\n".join(parts) if parts else "ï¼ˆç„¡å·¥å…·çµæœï¼‰"

    evidence_text = serialize_evidence(evidence)

    # ========== STEP 1: Chain-of-Thought (Thinking) ==========
    cot_thinking = ""
    try:
        cot_chain = build_cot_thinking_chain()
        cot_resp = cot_chain.invoke({
            "visible_text": visible[:3000],
            "urls": urls_str,
            "evidence": evidence_text,
        })
        cot_thinking = cot_resp.content if hasattr(cot_resp, "content") else str(cot_resp)
        
        log_decision({
            "time": datetime.datetime.utcnow().isoformat(),
            "phase": "cot_thinking",
            "cot_output": cot_thinking[:1000]  # è¨˜éŒ„å‰ 1000 å­—
        })
    except Exception as e:
        cot_thinking = f"æ¨ç†éç¨‹å‡ºéŒ¯ï¼š{str(e)}"
        log_decision({"time": datetime.datetime.utcnow().isoformat(), "phase": "cot_error", "error": str(e)})

    # ========== STEP 2: Final Analysis (JSON) ==========
    content = ""
    try:
        chain = build_analysis_chain()
        resp = chain.invoke({
            "visible_text": visible[:3000],
            "urls": urls_str,
            "evidence": evidence_text,
            "cot_thinking": cot_thinking,
        })
        content = resp.content if hasattr(resp, "content") else str(resp)
    except Exception as e:
        content = ""
        log_decision({"time": datetime.datetime.utcnow().isoformat(), "phase": "llm_error", "error": str(e)})

    # Try parse LLM JSON, fallback to minimal structure
    parsed = {}
    try:
        m = re.search(r"(\{[\s\S]*\})", content)
        jtext = m.group(1) if m else content
        parsed = json.loads(jtext)
    except Exception:
        parsed = {"is_potential_phishing": False, "risk_level": "low", "explanation": ["AI åˆ¤æ–·æ­£å¸¸æˆ–å›å‚³éŒ¯èª¤"], "confidence": 30}

    # RULE-CONFIDENCE HYBRID LOGIC
    # æ ¹æ“šæ¨¡å‹ä¿¡å¿ƒæ±ºå®š rule engine çš„å„ªå…ˆç´š
    final_decision = parsed.get("is_potential_phishing", False)
    final_level = parsed.get("risk_level", "low")
    final_conf = parsed.get("confidence", 30)
    final_explanations = parsed.get("explanation", [])
    if isinstance(final_explanations, str):
        final_explanations = re.split(r"[,ã€;ï¼Œ]", final_explanations)

    model_confidence = final_conf  # è¨˜éŒ„æ¨¡å‹åŸå§‹ä¿¡å¿ƒ
    
    # ä¿¡å¿ƒé–¾å€¼ï¼š70% ç‚ºåˆ†ç•Œç·š
    CONFIDENCE_THRESHOLD = 70
    
    # CASE 1: ç¡¬è¦å‰‡ï¼ˆhard_flagï¼‰ç¸½æ˜¯å¼·åˆ¶åŸ·è¡Œï¼Œç„¡è¦–æ¨¡å‹ä¿¡å¿ƒ
    if hard_flag:
        final_decision = True
        final_level = "high"
        final_conf = max(final_conf, 85)
        final_explanations = ["âœ“ è¦å‰‡åˆ¤å®šï¼šèº«ä»½é©—è­‰+ç·Šæ€¥èªæ°£ï¼ˆå¼·åˆ¶å„ªå…ˆï¼‰"] + final_explanations

    # CASE 2: æ¨¡å‹ä¿¡å¿ƒé«˜ï¼ˆâ‰¥ 70%ï¼‰-> æ¨¡å‹åˆ¤æ–·å„ªå…ˆï¼Œrule åªæä¾›è£œå……ç†ç”±
    elif model_confidence >= CONFIDENCE_THRESHOLD:
        # æ¨¡å‹é«˜ä¿¡å¿ƒåˆ¤æ–·ä¿æŒä¸è®Šï¼Œä½†å¯ä»¥ç”± rule æä¾›é¡å¤–è­‰æ“š
        if score >= 6:
            final_explanations = final_explanations + [f"âš  è¦å‰‡ç³»çµ±åŒæ™‚æ¨™è¨˜é«˜é¢¨éšªï¼ˆè©•åˆ† {score}/10ï¼‰"]
        elif score >= 4:
            final_explanations = final_explanations + [f"âš  è¦å‰‡ç³»çµ±æª¢æ¸¬åˆ°ä¸­åº¦é¢¨éšªï¼ˆè©•åˆ† {score}/10ï¼‰"]
        # æ¨¡å‹æ±ºç­–ä¿æŒä¸è®Šï¼Œä¿¡å¿ƒä¹Ÿä¸è®Šï¼ˆæˆ–ç•¥å¾®æå‡ï¼‰
        final_conf = min(final_conf + 5, 99)  # ç¨å¾®æå‡ï¼Œæœ€å¤š 99%

    # CASE 3: æ¨¡å‹ä¿¡å¿ƒä½ï¼ˆ< 70%ï¼‰-> rule engine å¯ä»¥å»ºè­°æˆ–èª¿æ•´
    else:
        # å¦‚æœ rule å¼·çƒˆæ¨™è¨˜ï¼ˆhard_flag å·²è™•ç†ï¼‰ï¼Œæˆ– rule åˆ†æ•¸å¾ˆé«˜
        if score >= 7:
            # rule åˆ†æ•¸å¾ˆé«˜ï¼Œä¸”æ¨¡å‹ä¿¡å¿ƒä½ -> è·Ÿéš¨ ruleï¼Œä½†åœ¨ explanation ä¸­è¨»æ˜
            final_decision = True
            final_level = "high"
            final_conf = 75  # æ ¹æ“š rule çµ¦äºˆ 75% ä¿¡å¿ƒ
            final_explanations = [f"ğŸ“‹ è¦å‰‡åˆ†æå»ºè­°ï¼ˆè©•åˆ† {score}/10ï¼Œæ¨¡å‹ä¿¡å¿ƒ{model_confidence}%ï¼‰"] + final_explanations

        elif score >= 5 and not final_decision:
            # rule ä¸­ç­‰é¢¨éšªï¼Œæ¨¡å‹èªªå®‰å…¨ä½†ä¿¡å¿ƒä½ -> èª¿æ•´åˆ° medium
            final_level = "medium"
            final_conf = 55
            final_explanations = [f"ğŸ“‹ è¦å‰‡ç³»çµ±æª¢æ¸¬ä¸­åº¦é¢¨éšªï¼ˆè©•åˆ† {score}/10ï¼‰"] + final_explanations

        elif score >= 4 and not final_decision:
            # rule è¼•å¾®é¢¨éšªï¼Œæ¨¡å‹èªªå®‰å…¨ä½†ä¿¡å¿ƒä½ -> ç¨å¾®æå‡é¢¨éšªç­‰ç´š
            if final_level == "low":
                final_level = "medium"
            final_conf = 50
            final_explanations = [f"ğŸ“‹ è¦å‰‡æª¢æ¸¬åˆ°æ½›åœ¨é¢¨éšªï¼ˆè©•åˆ† {score}/10ï¼‰"] + final_explanations

        # åŸŸåæª¢æŸ¥ï¼šåªåœ¨æ¨¡å‹ä¿¡å¿ƒä½æ™‚æ‡‰ç”¨
        if not final_decision or final_conf < 60:
            for u in urls:
                d = domain_of(u)
                if is_suspicious_tld(d) or contains_brand_typo(d):
                    final_decision = True
                    final_level = "high"
                    final_conf = 75
                    final_explanations = [f"ğŸ”´ åŸŸåç–‘ä¼¼é«˜é¢¨éšªï¼š{d}"] + final_explanations
                    break

    # Normalize
    final_explanations = [e.strip() for e in final_explanations if str(e).strip()]
    if not final_explanations:
        final_explanations = ["æœªç™¼ç¾å¯ç–‘ç‰¹å¾µ"]

    end = time.time()
    elapsed = end - start

    # Log full context for debugging / retraining
    log_decision({
        "time": datetime.datetime.utcnow().isoformat(),
        "phase": "final",
        "visible_snippet": visible[:500],
        "urls": urls[:5],
        "evidence": evidence,
        "rule": r,
        "cot_thinking": cot_thinking[:500],  # è¨˜éŒ„æ€è€ƒéç¨‹ï¼ˆå‰ 500 å­—ï¼‰
        "llm_raw": content,
        "final": {
            "is_potential_phishing": final_decision,
            "risk_level": final_level,
            "confidence": final_conf,
            "explanation": final_explanations
        },
        "elapsed": elapsed
    })

    return {
        "is_potential_phishing": final_decision,
        "risk_level": final_level,
        "confidence": final_conf,
        "explanation": final_explanations[:3],
        "evidence": evidence,
        "cot_thinking": cot_thinking,  # å®Œæ•´æ€è€ƒéç¨‹ç›´æ¥å›å‚³
        "elapsed_time": elapsed
    }
